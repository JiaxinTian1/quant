quant_type: int4
quant_target: sglang
original_dtype: bf16
model_type: deepseekv3
use_dist: True

global:
  weight:
    enable: False
  activation:
    enable: False
  algorithm: 
    minmax:
      is_sym: True
  
local:
  ffn.experts:
    weight:
      enable: True
      target_dtype: int4
      calibrator: minmax
      granularity: group
      is_sym: True
    activation:
      enable: True
      target_dtype: fp8_e4m3
      calibrator: minmax
      granularity: tensor
      is_sym: True


disable:
  ["lm_head", "ffn.gate"]


