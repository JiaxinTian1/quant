quant_type: int4
quant_target: sglang
original_dtype: bf16

global:
  weight:
    enable: false
  activation:
    enable: True
    target_dtype: fp8_e4m3
    calibrator: minmax
    granularity: channel
    is_sym: True
  algorithm: 
    minmax:
      is_sym: True
  
local:
  mlp.experts:
    weight:
      enable: True
      target_dtype: int4
      calibrator: minmax
      granularity: block
      is_sym: True

disable:
  ["lm_head", "mlp.gate"]

max_layers_per_subgraph: 5

is_training: False

